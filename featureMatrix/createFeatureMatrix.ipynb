{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.stem import SnowballStemmer\n",
    "# Initialize the Snowball Stemmer for English\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic frame for feature matrix\n",
    "# create list of all patient IDs that were used in annotation\n",
    "cohort = pd.read_csv('/home/jsearle/bigDrive/NAX/NLP-SAH_identification/code/test&trainCohorts/combined_cohort_train.csv')\n",
    "\n",
    "# read in annotations from downloaded file from arjun's tool\n",
    "annotations = pd.read_csv('/home/jsearle/bigDrive/NAX/NLP-SAH_identification/annotations/full_annotations_final.csv')\n",
    "annotations = annotations[['empi', 'annot']]\n",
    "\n",
    "# merge the two into a feature matrix with all patients and note date and text\n",
    "matrix = cohort[['BDSPPatientID', 'NoteDate', 'text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MGB for each patient check the allICDCodesMGB to find record of icd from +- 6 months of the note date\n",
    "ICDs = pd.read_csv('/home/cdac-c-15/Desktop/NAXCA/Cohort Creation Files/allICDCodesMGB.csv')\n",
    "ICDs = ICDs[ICDs['BDSPPatientID'].isin(set(matrix['BDSPPatientID']))]\n",
    "ICDs['ICD Date'] = pd.to_datetime(ICDs['ShiftedContactDTS']).dt.strftime('%Y-%m-%d')\n",
    "ICDs['ICD Date'] = pd.to_datetime(ICDs['ICD Date'])\n",
    "ICDs = ICDs[['BDSPPatientID', 'ICD Date']]\n",
    "ICDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIDMC for each patient check the allICDCodesMGB to find record of icd from +- 6 months of the note date\n",
    "ICDs = pd.read_csv('/home/cdac-c-15/Desktop/mimic-iii-clinical-database-1.4/DIAGNOSES_ICD.csv.gz', compression='gzip')\n",
    "dates = pd.read_csv('/home/cdac-c-15/Desktop/mimic-iii-clinical-database-1.4/ADMISSIONS.csv')\n",
    "ICDs = ICDs.merge(dates[['HADM_ID', 'ADMITTIME', 'DISCHTIME']], on='HADM_ID', how='left')\n",
    "ICDs = ICDs[['SUBJECT_ID', 'HADM_ID', 'ICD9_CODE', 'ADMITTIME', 'DISCHTIME']]\n",
    "ICDs = ICDs.rename(columns={'SUBJECT_ID': 'BDSPPatientID', 'DISCHTIME': 'Disch Date','ADMITTIME': 'Admit Date'})\n",
    "ICDs = ICDs[ICDs['ICD9_CODE'].str.contains(r'^(427\\.?5|I46)', regex=True, case=False, na=False)]\n",
    "print(len(ICDs))\n",
    "ICDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MGB add 1 or 0 to new column in matrix that denotes whether an icd is present +- 6 months from note creation date\n",
    "#merge the dfs on patient ID\n",
    "matrix = matrix.rename(columns={'patient id': 'BDSPPatientID', 'note date': 'Note Date'})\n",
    "matrix['Note Date'] = pd.to_datetime(matrix['Note Date'])\n",
    "ICDs['ICD Date'] = pd.to_datetime(ICDs['ICD Date'])\n",
    "\n",
    "merged_df = pd.merge(matrix, ICDs, on='BDSPPatientID')\n",
    "\n",
    "#check for date timeline\n",
    "merged_df['ICD'] = merged_df.apply(\n",
    "    lambda row: (row['Note Date'] >= row['ICD Date'] - pd.DateOffset(months=6)) and \n",
    "                (row['Note Date'] <= row['ICD Date'] + pd.DateOffset(months=6)), axis=1)\n",
    "matrix['ICD'] = matrix.apply(\n",
    "    lambda row: merged_df[(merged_df['BDSPPatientID'] == row['BDSPPatientID']) & merged_df['ICD']].shape[0] > 0, axis=1).astype(int)\n",
    "\n",
    "print(len(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIDMC add 1 or 0 to new column in matrix that denotes whether an icd is present +- 6 months from note creation date\n",
    "#merge the dfs on patient ID\n",
    "matrix['Note Date'] = pd.to_datetime(matrix['Note Date'])\n",
    "ICDs['Admit Date'] = pd.to_datetime(ICDs['Admit Date'])\n",
    "ICDs['Disch Date'] = pd.to_datetime(ICDs['Disch Date'])\n",
    "\n",
    "merged_df = pd.merge(matrix, ICDs, on='BDSPPatientID')\n",
    "\n",
    "#check for date timeline\n",
    "merged_df['ICD'] = merged_df.apply(\n",
    "    lambda row: (row['Note Date'] >= row['Admit Date'] - pd.DateOffset(months=6)) and \n",
    "                (row['Note Date'] <= row['Disch Date'] + pd.DateOffset(months=6)), axis=1)\n",
    "matrix['ICD'] = matrix.apply(\n",
    "    lambda row: merged_df[(merged_df['BDSPPatientID'] == row['BDSPPatientID']) & merged_df['ICD']].shape[0] > 0, axis=1).astype(int)\n",
    "\n",
    "print(len(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MGB for each patient check the ** to find record of cpt from +- 6 months of the note date\n",
    "CPTs = pd.read_csv('/home/cdac-c-15/Desktop/NAXCA/Cohort Creation Files/allEEGCodesMGB.csv')\n",
    "CPTs = CPTs[CPTs['BDSPPatientID'].isin(set(matrix['BDSPPatientID']))]\n",
    "CPTs['CPT Date'] = pd.to_datetime(CPTs['StartDTS'], errors='coerce')\n",
    "CPTs = CPTs[['BDSPPatientID', 'CPT Date', 'CPT']]\n",
    "CPTs.head()\n",
    "\n",
    "# add 1 or 0 to new column in matrix that denotes whether a cpt is present +- 6 months from note creation date\n",
    "#merge the dfs on patient ID\n",
    "CPTs['CPT Date'] = pd.to_datetime(CPTs['CPT Date'])\n",
    "matrix['Note Date'] = pd.to_datetime(matrix['Note Date'])\n",
    "\n",
    "MRI = CPTs[CPTs['CPT'].isin(list([95812,95813,95816,95819,95822]))]\n",
    "CT = CPTs[CPTs['CPT'].isin(set([95718,95719,95720,95721,95722,95723,95724]))]\n",
    "PET = CPTs[CPTs['CPT'].isin(set([95950,95951,95953,95957]))]\n",
    "\n",
    "merged_df = pd.merge(matrix, MRI, on='BDSPPatientID')\n",
    "\n",
    "#check for date timeline\n",
    "merged_df['MRI'] = merged_df.apply(\n",
    "    lambda row: (row['Note Date'] >= row['CPT Date'] - pd.DateOffset(months=6)) and \n",
    "                (row['Note Date'] <= row['CPT Date'] + pd.DateOffset(months=6)), axis=1)\n",
    "matrix['MRI'] = matrix.apply(\n",
    "    lambda row: merged_df[(merged_df['BDSPPatientID'] == row['BDSPPatientID']) & merged_df['MRI']].shape[0] > 0, axis=1).astype(int)\n",
    "\n",
    "merged_df = pd.merge(matrix, CT, on='BDSPPatientID')\n",
    "#check for date timeline\n",
    "merged_df['CT'] = merged_df.apply(\n",
    "    lambda row: (row['Note Date'] >= row['CPT Date'] - pd.DateOffset(months=6)) and \n",
    "                (row['Note Date'] <= row['CPT Date'] + pd.DateOffset(months=6)), axis=1)\n",
    "matrix['CT'] = matrix.apply(\n",
    "    lambda row: merged_df[(merged_df['BDSPPatientID'] == row['BDSPPatientID']) & merged_df['CPT']].shape[0] > 0, axis=1).astype(int)\n",
    "\n",
    "merged_df = pd.merge(matrix, PET, on='BDSPPatientID')\n",
    "#check for date timeline\n",
    "merged_df['PET'] = merged_df.apply(\n",
    "    lambda row: (row['Note Date'] >= row['CPT Date'] - pd.DateOffset(months=6)) and \n",
    "                (row['Note Date'] <= row['CPT Date'] + pd.DateOffset(months=6)), axis=1)\n",
    "matrix['PET'] = matrix.apply(\n",
    "    lambda row: merged_df[(merged_df['BDSPPatientID'] == row['BDSPPatientID']) & merged_df['CPT']].shape[0] > 0, axis=1).astype(int)\n",
    "\n",
    "print(len(matrix))\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIDMC for each patient use regex to search for cpt within note text of matrix to fill in matrix value\n",
    "matrix['MRI'] = matrix['text'].str.contains(r'c?MRI', regex=True, case=False, na=False).astype(int)\n",
    "matrix['CT'] = matrix['text'].str.contains(r'c?CT', regex=True, case=False, na=False).astype(int)\n",
    "matrix['PET'] = matrix['text'].str.contains(r'c?PET', regex=True, case=False, na=False).astype(int)\n",
    "print(len(matrix))\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.to_csv('/home/cdac-c-15/Desktop/NAXCA/Test and Train Groups/trainBIDMC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [['BDSPPatientID', 'annot', 'Note Date', 'text', 'ICD', 'MRI', 'CT', 'PET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem note text \n",
    "matrix = pd.read_csv('/home/cdac-c-15/Desktop/NAXCA/Test and Train Groups/allTrainingMatrix.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "matrix['text'] = matrix['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use if have edited key words, will stem the text\n",
    "# keyWords = pd.read_csv('/home/cdac-c-15/Desktop/NAXCA/sampleCohortGenerator/generator program files/posPattern.csv')\n",
    "# keyWords['KeyWord'] = keyWords['KeyWord'].apply(lambda x: preprocess_text(x))\n",
    "# keyWords.to_csv('/home/cdac-c-15/Desktop/NAXCA/sampleCohortGenerator/generator program files/posPattern.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the positive regexes and the negative regexes based on the csv of key words\n",
    "def create_neg_regex_dict(phrases):\n",
    "    # Define the template for regex patterns\n",
    "    template = r\"(?:(?:no|not|n't|absent|h/o|pmh|negative|history of|unlikely|without|lack|deferred)[^(.|,)]{{0,30}}{phrase})|(?:{phrase}\\s*[^.]{{0,80}}(deferred|absent|unlikely))\"\n",
    "    \n",
    "    # Function to process each phrase into a regex-compatible format\n",
    "    def process_phrase(phrase):\n",
    "        # Split the phrase into words and create a regex-friendly version\n",
    "        words = phrase.split()\n",
    "        processed_words = [f\"{word}[a-z]*\" for word in words]\n",
    "        return r\"\\s*\".join(processed_words)\n",
    "    \n",
    "    # Dictionary to store the regex patterns\n",
    "    regex_dict = {}\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        processed_phrase = process_phrase(phrase)\n",
    "        pattern = template.format(phrase=processed_phrase)\n",
    "        regex_dict[phrase] = pattern\n",
    "    \n",
    "    return regex_dict\n",
    "\n",
    "def create_pos_regex_dict(phrases):    \n",
    "    # Function to process each phrase into a regex-compatible format\n",
    "    def process_phrase(phrase):\n",
    "        # Split the phrase into words and create a regex-friendly version\n",
    "        words = phrase.split()\n",
    "        processed_words = [f\"{word}\" for word in words]\n",
    "        return r\"\\s*\".join(processed_words)\n",
    "    \n",
    "    regex_dict = {}\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        processed_phrase = process_phrase(phrase)\n",
    "        regex_dict[phrase] = processed_phrase\n",
    "    \n",
    "    return regex_dict\n",
    "\n",
    "# Example usage\n",
    "keywords_list = []\n",
    "\n",
    "# Open the CSV file and read line by line\n",
    "with open('/home/cdac-c-15/Desktop/NAXCA/sampleCohortGenerator/generator program files/posPattern.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # Skip the header if it exists\n",
    "    for row in reader:\n",
    "        if len(row) > 1:  # Check if there are columns other than the index\n",
    "            keywords_list.append(row[1])  # Assuming 'KeyWords' is the second column\n",
    "\n",
    "neg_regex_dict = create_neg_regex_dict(keywords_list)\n",
    "pos_regex_dict = create_pos_regex_dict(keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BDSPPatientID</th>\n",
       "      <th>annot</th>\n",
       "      <th>Note Date</th>\n",
       "      <th>text</th>\n",
       "      <th>ICD</th>\n",
       "      <th>MRI</th>\n",
       "      <th>CT</th>\n",
       "      <th>PET</th>\n",
       "      <th>\\bbrainstem\\b</th>\n",
       "      <th>...</th>\n",
       "      <th>\\bpulseless\\b</th>\n",
       "      <th>\\bsuspicion for anox brain injuri\\b</th>\n",
       "      <th>\\bcpt\\b</th>\n",
       "      <th>\\bnoxious stimuli\\b</th>\n",
       "      <th>\\bhypox\\b</th>\n",
       "      <th>\\bpmi\\b</th>\n",
       "      <th>\\bparaphas error\\b</th>\n",
       "      <th>\\bbrainstem function\\b</th>\n",
       "      <th>\\brewarm\\b</th>\n",
       "      <th>\\bvasodilatori shock\\b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>2192-08-15</td>\n",
       "      <td>admiss date : [ * * 2192-8-9 * * ] discharg da...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43126</td>\n",
       "      <td>1</td>\n",
       "      <td>2124-09-26</td>\n",
       "      <td>admiss date : [ * * 2124-8-21 * * ] discharg d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69917</td>\n",
       "      <td>0</td>\n",
       "      <td>2167-02-13</td>\n",
       "      <td>admiss date : [ * * 2167-2-6 * * ] discharg da...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13757</td>\n",
       "      <td>1</td>\n",
       "      <td>2134-04-01</td>\n",
       "      <td>admiss date : [ * * 2134-2-16 * * ] discharg d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22285</td>\n",
       "      <td>1</td>\n",
       "      <td>2125-07-24</td>\n",
       "      <td>admiss date : [ * * 2125-7-17 * * ] discharg d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  BDSPPatientID  annot   Note Date  \\\n",
       "0           0            106      1  2192-08-15   \n",
       "1           1          43126      1  2124-09-26   \n",
       "2           2          69917      0  2167-02-13   \n",
       "3           3          13757      1  2134-04-01   \n",
       "4           4          22285      1  2125-07-24   \n",
       "\n",
       "                                                text  ICD  MRI  CT  PET  \\\n",
       "0  admiss date : [ * * 2192-8-9 * * ] discharg da...    1    0   1    0   \n",
       "1  admiss date : [ * * 2124-8-21 * * ] discharg d...    1    1   1    1   \n",
       "2  admiss date : [ * * 2167-2-6 * * ] discharg da...    1    1   1    0   \n",
       "3  admiss date : [ * * 2134-2-16 * * ] discharg d...    1    0   1    1   \n",
       "4  admiss date : [ * * 2125-7-17 * * ] discharg d...    1    1   1    0   \n",
       "\n",
       "   \\bbrainstem\\b  ...  \\bpulseless\\b  \\bsuspicion for anox brain injuri\\b  \\\n",
       "0              0  ...              0                                    0   \n",
       "1              0  ...              0                                    0   \n",
       "2              0  ...              0                                    0   \n",
       "3              0  ...              0                                    0   \n",
       "4              0  ...              0                                    0   \n",
       "\n",
       "   \\bcpt\\b  \\bnoxious stimuli\\b  \\bhypox\\b  \\bpmi\\b  \\bparaphas error\\b  \\\n",
       "0        0                    0          0        0                   0   \n",
       "1        0                    0          0        0                   0   \n",
       "2        0                    0          0        0                   0   \n",
       "3        0                    0          0        0                   0   \n",
       "4        0                    0          0        1                   0   \n",
       "\n",
       "   \\bbrainstem function\\b  \\brewarm\\b  \\bvasodilatori shock\\b  \n",
       "0                       0           0                       0  \n",
       "1                       0           1                       0  \n",
       "2                       0           0                       0  \n",
       "3                       0           0                       0  \n",
       "4                       0           0                       0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to check for the presence of patterns and determine the final occurrence\n",
    "def check_patterns(text, neg_regex_dict, pos_regex_dict):\n",
    "    matches = {key: 0 for key in set(neg_regex_dict) | set(pos_regex_dict)}  # Initialize matches dictionary with 0\n",
    "    for key in matches:\n",
    "        neg_match = [m.end() for m in re.finditer(neg_regex_dict.get(key, ''), text)]\n",
    "        pos_match = [m.end() for m in re.finditer(pos_regex_dict.get(key, ''), text)]\n",
    "        # Determine the latest match between negated and non-negated patterns\n",
    "        latest_neg_match = max(neg_match, default=-1)\n",
    "        latest_pos_match = max(pos_match, default=-1)\n",
    "        # Final assignment logic\n",
    "        if latest_neg_match != -1 and (latest_pos_match == -1 or latest_neg_match >= latest_pos_match):\n",
    "            matches[key] = -1\n",
    "        elif latest_pos_match != -1:\n",
    "            matches[key] = 1\n",
    "    return matches\n",
    "\n",
    "pattern_features = matrix['text'].apply(lambda note: check_patterns(note, neg_regex_dict, pos_regex_dict))\n",
    "pattern_columns = pd.DataFrame(pattern_features.tolist())\n",
    "result = pd.concat([matrix, pattern_columns], axis=1)\n",
    "\n",
    "print(len(result))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/home/cdac-c-15/Desktop/NAXCA/Test and Train Groups/allTrainingMatrix.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideas:\n",
    "# function to check gcs score whether it's positive for <8 and negative for >7\n",
    "# only run code on part of note after cardiac, arrest, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allBIDMC = pd.read_csv('/home/cdac-c-15/Desktop/NAXCA/Test and Train Groups/testBIDMC.csv')\n",
    "# allMGB = pd.read_csv('/home/cdac-c-15/Desktop/NAXCA/Test and Train Groups/testMGB.csv')\n",
    "# allBIDMC = allBIDMC[['SUBJECT_ID', 'TEXT', 'CHARTDATE']]\n",
    "# allMGB = allMGB[['BDSPPatientID', 'text', 'Note Date']]\n",
    "# allBIDMC = allBIDMC.rename(columns={'SUBJECT_ID': 'patient id', 'TEXT': 'text', 'CHARTDATE': 'note date'})\n",
    "# allMGB = allMGB.rename(columns={'BDSPPatientID': 'patient id', 'Note Date': 'note date'})\n",
    "\n",
    "# trainingData = pd.concat([allBIDMC, allMGB])\n",
    "\n",
    "# trainingData.to_csv('/home/cdac-c-15/Desktop/NAXCA/Test and Train Groups/allTesting.csv')\n",
    "# print(len(pd.concat([allBIDMC, allMGB])))\n",
    "# trainingData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing\n",
    "\n",
    "# nested k-fold cross validation\n",
    "#     for i in range(K)       #evaluate out of sample perf\n",
    "#       for hp in hyperparameters:\n",
    "#         for j in range(K)   #decide the best hyperparameter\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
